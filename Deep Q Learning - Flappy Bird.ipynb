{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/YData123/sds365-sp22/main/assignments/assn4/images/flappy_bird_demp.gif\" width=\"144\" height=\"256\"/>\n",
    "\n",
    "The implementation is based these references:\n",
    "- [DeepLearningFlappyBird](https://github.com/yenchenlin/DeepLearningFlappyBird)\n",
    "- [Deep Q-Learning for Atari Breakout](https://keras.io/examples/rl/deep_q_network_breakout/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pygame in /Users/aj/anaconda3/lib/python3.11/site-packages (2.5.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: opencv-python in /Users/aj/anaconda3/lib/python3.11/site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /Users/aj/anaconda3/lib/python3.11/site-packages (from opencv-python) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "pygame 2.5.2 (SDL 2.28.3, Python 3.11.5)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n",
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    }
   ],
   "source": [
    "%pip install pygame\n",
    "%pip install opencv-python\n",
    "import sys\n",
    "sys.path.append('/utils')\n",
    "import os\n",
    "os.chdir('/utils')\n",
    "import numpy as np\n",
    "import cv2\n",
    "import wrapped_flappy_bird as flappy_bird\n",
    "from collections import deque\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of image: (288, 512, 3)\n",
      "reward:  0.1\n",
      "terminal:  False\n"
     ]
    }
   ],
   "source": [
    "num_actions = 2\n",
    "\n",
    "# initiate a game\n",
    "game = flappy_bird.GameState()\n",
    "\n",
    "# get the first state by doing nothing\n",
    "do_nothing = np.zeros(num_actions)\n",
    "do_nothing[0] = 1\n",
    "image, reward, terminal = game.frame_step(do_nothing)\n",
    "\n",
    "print('shape of image:', image.shape)\n",
    "print('reward: ', reward)\n",
    "print('terminal: ', terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(587):\n",
    "    \n",
    "    # choose a random action \n",
    "    action = np.random.choice(num_actions)\n",
    "    \n",
    "    # create the corresponding one-hot vector\n",
    "    action_vec = np.zeros(num_actions)\n",
    "    action_vec[action] = 1\n",
    "\n",
    "    # take the action and observe the reward and the next state\n",
    "    image, reward, terminal = game.frame_step(action_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQgAAAGiCAYAAAAbcVh3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA5PklEQVR4nO3de5RU5YEu/Oete1/L7ka6aC4GtYlJGh2DBsOYgOE2RGQ85hycMGs+J8t1lobISQ9wTBj+CM7J0Ixros6KE7PiMGLi4mPOtxSTWck4tJ8G4sfnHESMgB6iEbl22wGbqr7Uvd7zR9Xetfeu/VZXde2qovH5rVXQVfvdxa6i9tPvfm8lpJQSREQ2XPU+ACK6fDEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISKmuAfGjH/0Ic+fORSAQwIIFC/Cb3/ymnodDRBZ1C4h/+Zd/QW9vL7Zu3YojR47gS1/6ElatWoXTp0/X65CIyELUa7LWwoUL8fnPfx5PPfWU/thnPvMZ3H333ejr66vHIRGRhace/2gikcDhw4fx3e9+1/T4ihUrcPDgwYLy8Xgc8Xhcv5/JZPDxxx+jo6MDQoiqHy/RlURKiZGREXR1dcHlKn4RUZeAuHDhAtLpNDo7O02Pd3Z2YnBwsKB8X18fHnnkkVodHtEnwpkzZzBr1qyiZeoSEBrrb38ppW2NYMuWLdi4caN+PxwOY86cOVU/Pqe5XS40+QO4+49uhhBAKBDDd64/AQBIwIVRePGjgYW4/vblWHv/XwAAXnr+X/HL/+dFvHjgJcSTCWQuw+U7utquxq3XzQe+9CGEP1Ow3efzoMHvg8/rRUOjH00NAQT8PjQ2+BFsbkLA50VDwI/m5gb4/T4EvF4EAtnyQgDxZAqxWAKJZBLRaByj4zHEYglE43GER8YRi8cxNpzCu7sE/tfv38bA8IU6vAuXL+v/TzKewS8fP42WlpYJ961LQEybNg1ut7ugtjA0NFRQqwAAv98Pv99fq8Ormnldc3Hrp67BP33hMAQARNMQR0YBAL9FB7bj8/jBc09ixuyZelD+l79ch69+bQ2Sa9bh0HtHceoP5+v3AhRcwgWvxwP43RCBwu0+nxtevxterxv+Bg8CDR40BLxoaPQh0ORBQ8CHxoAPTU1+BPw++P1eNAb8ekD4kil4fALxuAsuD5BxS7i8gPBkkMx4IdwZpKKA1yPgEuy5t1L9/5RyeV6Xd9Pn82HBggXo7+83Pd7f349FixbV45Cq7pbrerD20x6sv/b3ECfGIU6MQZyMWUoJXBg9j0jsY/2R11/5DZ554sf4b9/7DtasWo0br/l0bQ/cSYbPo5QSkICQApCAlKbNxZ8iuyukEIDI/VyVA6a6xe3GjRvxT//0T/jnf/5nvPvuu/irv/ornD59Gg8++GC9DqkqfB4vOpqDuL09gD9uTuAW7x8gLiaBiyngUqqg/HhyBPFUVL9/9sPT+O1/HMYXvrwI867vRmewo5aHX2WFp7VAYVCIgo2Mg1qpWxvEvffei4sXL+Jv/uZvMDAwgJ6eHvzqV7/CNddcU69Dqoqutum49brP4BH8Gk0fpYCP6n1EdZQ7r6UpBWT2vM89lqtQKHbObRE2WcHOrKqoayPl+vXrsX79+noeQk1kIPA/cAtclo/+dETRi7cBAN0I42/xOnb//T9j1pcWYdnalehqnYula/4Et3zpNgjX1D8D9Etew7kuhcj+mLvMUFUOLJmSLSylHjZT/925PNU1IK50ncEOzOvuxsIv32673T82jNcPfYTPYBhBJHA9Iphz6m0kW304HGrDmebzELlGt4/ODWJo4CN43B7MbO/Ehcgw4qlELV9ORYTi54nKmh9V7MkrjqphQFTRTZ+6AWu+uhr/9b9vAGBuNZZS4typM/jv/9c72Io3cCOyDZP34QReOTqKnxwdsn3ORr8ft827Eb959zCGwh/blpkK8pcI2bO76Dlu2WisiGjVjsuw9/eKwICostH4JZwe/t+YddU8uIVbf/zi+ADOhz8oKP8IbsHMHh9+uPxS0ef9wZ7P4MDRCA69f9TpQ3acQGFPg3bf2ABZpI5g2lkCgBCmwBXmZyOHMCCq6NQfzuO3vz2GaT+fhvbGdyEMnUajiUsY/8M53Jb6EC7E8IEI4F13J667yQNPqwuvH/cVfe7fD4RxIXKpyq/AWcYuSggBCJFtQzAVKELCUFOQvLKoAQZEFZ04fxKx/z+O6OAIXMIFN6SpoXKaHMODyd8BAN5xteP/dl2P//HFEbx/NoOfvtRk+5xSAqm0wMF33sVQZGpcYhT8bs/dEdrZLgChP2izv6Fqofd2ALnBE1rQsPZQDQyIKjv9h/M4d/EjrPr8l7FYnsaXUif1bcaP9NzMx/hO7FU88ZMv4rN/5MZPHrY/+c9fcGPrT66q7kFXWfZ1G/onZbZNRppqCFbSECzZW/bhojtRhRgQVSYBpDJpHD/zPpqDPiRbrgcAfC49iFkyopdzAXAhg9tiJxE71Yb/+Uq77fNdjCTx9qkTGImN1+DonaPHgeIXvcAEbRCGLVLfgbWGamNA1MgHH52B23UNws0zAQCNGEcr4gXlrktfxFvn3PjlgP2IydFoCu8NnKrqsTrO1O1QuKnsbk+R/YPxUH0MiBp6b+CUfnJ/dO3n8KmrP2Nb7uQfzuHNDw7U8tBqy3qJAORHUSrmVhgfM7VrCgEBkX8+chQDok4++OgMBi/ZT0sei0dtH5+q9FqCcbIW8r0Z2dGUuZM8nxf2zwEtUyxtD6xOVAUDok6GxyIYHotMXHCKK5hbJY1bCs/q/KP2Z7ws+IEDKauJk+epJqwnsXU0pNDme1urGtYnMc7hECI7bVwfXEFOY0BQVSnPW2OX5UR76es/5PfVez1yAyMkLzGqggFBVVcQEkIbByltGyQVe2V31cZtg+0PtcCAoJpQ9nSaVpnKtztKRRnzc0kUSRhyAAOCqi77S1/o57Fx3QetyUFqA58UI65NvRhCX2YmXwdhSFQFA4JqRNF/aaEaz6Bq5FSXICcwIKi2tJlbhjNcm1shis6pKJy9WcooTKoMA4Jqwngym05qfSRl8QUhRMHQam3JOWG7lZzBgKCqsj1tjV2beruDtBaZ8GcIMUGtgyrFgKCqkoa/9VmYuQeK/c431zKsT2ItMcGT0aQxIKjqbJod8tty60BoUyuUFYKCakR+HEXuiRw6WjJiQFBNKGdnCkO/Zgmtjvrm3BNo61JyJGV1MCCo+nInr3LwUykLQhQLEFFCstCkMCCoNoydFKYOC5n7U6jP/yL3eWFRXQwIqg1p+RvWxWzLONW1hWtFrnNTmw1KjmNAUPVNdO5aQqPYurX2vRhULQwIqqmCk19bBkLrwbCbrGXzHPl5HXYL0ZFTGBBUdabvsgDMZ79xZepcObu2CFPlQYLL3dcIA4JqQ7GidSnlStvMsKgGBgRVn80sK9sBTkVmcuZXkNKeQ5hqH4yH6mBAUO0YejL0ad2GSVrC8oW81l21wVDZXbKXGPkJYGyDqAYGBNWFceSj3qSg37OnrXYttXtCsOZQZQwIqjprZaFgZKVhqSmb4RIw7KLfsxu6Tc5jQFDtGS4xtBmexiYF65q0xv20QVEFFxS8wqgKBgTVjGn8QsFWc63A2hRROH5C6+bkPIxqYkBQjUnTuhAChbUB1X3JLKg5BgTViCjsqgQM60BIfW3KYvRwMbZnCOZGtTAgqEbsz3ytViByPRKquRimZe8Nf4vcpYbkqMqqYEBQzWRP/okuKIqzhgRVFwOCasTaUWleHUoavrxXGRmmhS2FPuUbRQZYUWUYEFR1xoVhtB+1gVF27QjKHk4tVbSuTskaRbUxIKhmsue3zfL2tuvaF9YIRMEdkd2hhMZNmhwGBFVdfuWo/EhJ/ZLA8G29xdoZTUtYGtetk3bjKskpDAiqCWMDZfbLd3MntdBmWKDkLktTkAgBKQRXta4ST70PgK58qXQasXgCyVQKiUQSo+MxeNxueD1u+P0+/WefzwOP2w137r7b5QIEkE5nkEqlkc5k/44nkkil0/rPyVQKiREAaK/3S73iMCCoIl63Bx537mOUdNv+Jk8BSCEDIJO7VwVxN4B2eNxeeN0eJNNV+nc+YRgQVJEvfeYWtDW1AhDA/zenzkcjcMu1n8PH02fh1eP/UedjuTIwIKhi4qo4cM2leh8GAEB8eBUwWu+juHIwIKhyDUmIrhHbTdk1IHIDmXJDql25gU3mnwGXy6X/LET+Z2N55O4D2eeVkPpcDiklLg0L4FwtX/yVjQFBVeNyCbjdLng9Hvi8Xnjcbvj8Xvh9Xvg8Hvi8HjQE/PD5sj83Bvzw+bzweT0I+P3w+7zwejwI5PbxeNzweDzwebMNmC6XCymtATOdRiKZwv88+Tucf+dkvV/6FYPdnFRFNvOzrYOahOmv0pjmfee/5ZsTtpzHgKCaKhwNWe7+lhBgJlQVA4KqSzV3u6BYkbSwbBIiPylcGG8cLOU4BgTVRL72L21DI9vcaHeGFxa2Tt1QL2NHlWJAUNWpV4oTpjNcmLeYfpBawWK1BCaE4xgQVEWFZ392OQe7pWMErGe43dJ0xb/+m5zGgKAqErYNA9JSxPZxGFsZCp/W9LMAJ2tVCQOCqsjaQmA+5a1LPxhXhTKtEyEB/SvCTTfD0+bnlJODGBBUXcaFpCaz+rTNmAmqHQYEVZG5eVIfIJUb6GRuYrBfMUYroy0xly1sadvg92VUTdkBceDAAdx1113o6uqCEAIvvviiabuUEtu2bUNXVxcaGhqwZMkSHD9+3FQmHo9jw4YNmDZtGpqamrBmzRqcPXu2ohdC9SMg4Ha5ckOnfWhuDOCqYDM6rmrBtLYgpne0oXNaG0JXtyM0vR0zOtvRNb0dM6a3o2t6h36bMb0DM6a1o3NaGzo7rkKwpRGNjX40NPgRaPAj4PfC5/NCCIF0OoN4IoloNJ69jccwNhZDKp2u99txRSl7LsbY2BhuuukmfOMb38DXvva1gu2PPvooHnvsMezatQvz5s3D97//fSxfvhwnTpxAS0sLAKC3txf/+q//ij179qCjowObNm3C6tWrcfjwYbjd7spfFdVWygWM+uHyuuFyubILvuTmUXjcbnikF560B26PG+60F66UF8LjBhJeyIQPaY8bKY8bSZ8L0i2Q8gikvRKpVBoSEh6vhNedhtsl4HK5kc4tHpPOZJDUF4/JIJ5MIjbKgHBS2QGxatUqrFq1ynablBJPPPEEtm7dinvuuQcA8Oyzz6KzsxO7d+/GAw88gHA4jJ07d+JnP/sZli1bBgB47rnnMHv2bLz88stYuXJlBS+H6kFeaETqQOMES8FIaEvHANFaHBY5wNHZnCdPnsTg4CBWrFihP+b3+7F48WIcPHgQDzzwAA4fPoxkMmkq09XVhZ6eHhw8eNA2IOLxOOLxuH4/Eok4edhUgTdPvgPvZVbrS/IywzGOBsTg4CAAoLOz0/R4Z2cnTp06pZfx+Xxoa2srKKPtb9XX14dHHnnEyUMlh1waY1hfyarSi2H9liMp5YTffFSszJYtWxAOh/XbmTNnHDtWIlJzNCBCoRAAFNQEhoaG9FpFKBRCIpHA8PCwsoyV3+9Ha2ur6UZE1edoQMydOxehUAj9/f36Y4lEAvv378eiRYsAAAsWLIDX6zWVGRgYwLFjx/QyROSMrrbpmB7syN453wp5uhXybEvJ+5fdBjE6Oor3339fv3/y5Em89dZbaG9vx5w5c9Db24vt27eju7sb3d3d2L59OxobG7Fu3ToAQDAYxP33349Nmzaho6MD7e3t2Lx5M+bPn6/3ahCRM26YeS3am1uzA8neywVFqvSvBCg7IN544w3ccccd+v2NGzcCAO677z7s2rULDz/8MKLRKNavX4/h4WEsXLgQ+/bt08dAAMDjjz8Oj8eDtWvXIhqNYunSpdi1axfHQBBVw/QxYP5H+fvxDHCotF2FnIIL+UUiEQSDwXofBtFl7ys9t6H9ehfEH+XbBZOxDF7c8SHC4fCE7Xmci0FESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJGSoytKEdHlRwgBj9sNr9cDj9uFjL/0fRkQRFc4OeJD+ndtgNuFtBBIpTIl78uAILqCpdIpJC4J4FKz/lgyXcX1IIho6jjw7hsV7c9GSiJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESmVFRB9fX249dZb0dLSgunTp+Puu+/GiRMnTGWklNi2bRu6urrQ0NCAJUuW4Pjx46Yy8XgcGzZswLRp09DU1IQ1a9bg7Nmzlb8aInKWLMPKlSvlM888I48dOybfeusteeedd8o5c+bI0dFRvcyOHTtkS0uLfP755+XRo0flvffeK2fMmCEjkYhe5sEHH5QzZ86U/f398s0335R33HGHvOmmm2QqlSrpOMLhsATAG2+8VXALh8MTnmtlBYTV0NCQBCD3798vpZQyk8nIUCgkd+zYoZeJxWIyGAzKH//4x1JKKS9duiS9Xq/cs2ePXubcuXPS5XLJl156qaR/lwHBG2+V30oJCA8qEA6HAQDt7e0AgJMnT2JwcBArVqzQy/j9fixevBgHDx7EAw88gMOHDyOZTJrKdHV1oaenBwcPHsTKlSsL/p14PI54PK7fj0QilRw2Oeiaq7sQ8PrrfRgmsUQcpy6cr/dhXBEmHRBSSmzcuBG33347enp6AACDg4MAgM7OTlPZzs5OnDp1Si/j8/nQ1tZWUEbb36qvrw+PPPLIZA+Vqui6zjnoaA3C48s2Zwltg8jf0x6Thj9NpOFRKU0lpDTslfsj/7PhvvZYRuBiJMyAcMikA+Khhx7C22+/jddee61gmxDCdF9KWfCYVbEyW7ZswcaNG/X7kUgEs2fPnsRRUzVce0sLVnxrFhr8Xng8bng9Hvh8XnjcLrjdbng8bqQzaaTTGSRTaSSTKQgBeD0eJOJJJNNppFIpRGNJJFIpJJIpxGJxxBNJJFNJROMJxOJJJJMpxBNpxGLx7POkUojF40il0kilM0gkU0gdng6wgumYSQXEhg0b8Itf/AIHDhzArFmz9MdDoRCAbC1hxowZ+uNDQ0N6rSIUCiGRSGB4eNhUixgaGsKiRYts/z2/3w+///KqxlKex+NGS0sAfr8XHrcbHrcbPm/2oyWlRFqmkUqnsidxKolEMoV0OoOMlIjF40gm00gmkxiPJZBIJpFIpvWASKRSiCcSiMeTSObCIx5PIZVOI527ZaREJiORkRlIuxoKTVpZ3ZxSSjz00EN44YUX8Morr2Du3Lmm7XPnzkUoFEJ/f7/+WCKRwP79+/WTf8GCBfB6vaYyAwMDOHbsmDIg6PLmdrng93vh83nh83ng83ng8bjhcmVrhKlUOhsCiSQSiRTi8STGY3GER8YQjozh0sgohiOjGI6MYDg8iuHwCD6OjGI4PIpL2i0yivDIGCIjYxgZG8foeBRj0RhiiWzgpHJBQc4qqwbxrW99C7t378bPf/5ztLS06G0GwWAQDQ0NEEKgt7cX27dvR3d3N7q7u7F9+3Y0NjZi3bp1etn7778fmzZtQkdHB9rb27F582bMnz8fy5Ytc/4VUtWZ2gCk8QEBCAEIQApA5i4hZeGegBAQsFyaCgmIXBuEMLdD2LZlkOPKCoinnnoKALBkyRLT48888wz+8i//EgDw8MMPIxqNYv369RgeHsbChQuxb98+tLS06OUff/xxeDwerF27FtFoFEuXLsWuXbvgdrsrezVUXwVNSLkTWQ8OaSmX38Hul7/IPwOENLR7CmHYStUkpJx69bJIJIJgMFjvwyAAX+m5DX/8J3Pxn797PXx+LzwuV7YdwuNGJpNBOpNBMpltO0il0kikUnqDYyKRRDQWz7YrJJOIxRLZdodkCrF4AvFEItsGEc9emqRSqWw7RCrb4JnJZAqORx6ZgYvvp/Dq8f+ow7sxtYTDYbS2thYtw7kYVDHt97mw+1Ujoa5ZWJ6j2HObd+clRq0wIKhiRU/X3NktbM9043OYLxmk9pgUpsfyT1q825ycwYAgZxQ7X2W2gN4ImbtvDJXCFgX7yGG9obYYEFQx4+9z6+92/Wdp/NsuTeyuRYwtk6wz1AMDgiqmdVDonRWGXgqp35m43UBYt+t9mwUFqUYYEFSxic5XmW/GnKCc5Y5QxQobKWulotmcRACQyUgkUykIIZDJuJDOSGQ8EulMBul0dhRldr5EGolktqsymbuv3dLpTPaWyejdozKTgZQSmeyyBIyEOmBAUMVOfHAGf/+TN8wP2oxjsh1BKQsegTa4ioFQfwwIqpiM+JA61lHvw8iK+ACk6n0UVwwGBFUklogjHm6AfzwIBOp4YkoAcQ9iySRiyfiExak0DAiqyMHfHcGs9k7cNu8m4LYzgD9dnwOJeYD9n8KRk8dx7uOh+hzDFYgBQY6Z0zUdgaALfq8XjY0B+L0eeL1eNAZ88Pm82YVkvNmp4FIC6XQ6tyhMdq5GNBpHPJlCIpnE+HhMXw8illswJpVKZaeNpwprKmyvqA4GBDmmpbkRzUEvGgN+BFua0BDwI+D3obW5AQ0BP/w+LxoCfvi8HkgJJJIpjMdiiMeTiCUSGBkZx3gsjmg8gcjIWHa9h1gCLiEgc2Om0unCCVpUPRwHQY7JLt8gTXO3J1hpMM+yLiVEfpBUdgQF6wj1wBoEOUZfFEYIfcalLOzRtGWazKXvbyph+JNKdet189Ha2Gx6LJVOYf87h0ranwFBdWIYDTnBWS9Zf5i0loYmzJ7TjhnzGuF2ueByCSQSDAiqA9OsC5EbYm25VCi2j2kFOthfnjAoyhe6vhErH8qvOh6PprHjH0rblwFBjpG59gehzdzSaglF14EwFMutX6l914Vy4ieVxet146rWRvh8PrjdLrhFsuR92UhJVWNdOXLC3/7GKaGGfXiBURkBAeFyQQgBV+5WKgYEOSfXQCmFeX3qYsvLGud5SsNjOs7JqFgl7x8DgpxlWMi61HZImVtZTghh7s2wNkxQZSaxUh8DgqpA6t+Hod1F4Y/Z+6YA0doe8p9iwfUnK5Zr1pnUMhoMCHKYdaVJ6N0RwlKq1EZIxoMzJvM+MiDIOTbrP0ihNTHafzz1SoY2AFNqXZxCX1GKKlNJbxADghyXrdJqC81J0+WDsYxpoduC9geph4WxKYK1ifJV8p4xIKiKSuzgNA6QsgyWIodMsirGgCAHyfyfIlt3MM7dUjU3ZlfFNvRn5nbI927kd+QlR/kKYrqM5GVAkIMMnzzLrM4JG9BNAydyjZoyezPO2ypjjA/lCNPf5b2BHGpNjin46In8X6qPpSo0WFNwTnh0DO+8fwoetxtulwux8dKXBmRAUHVo1wWGZLDt5jQ+oP+cv8Qo2I/JUbZzgxfw/L8d0+8n46UvusOAIAfJfBclitcc9CHW2pgqkW9zYOukw4aagF/Pzd9PpQB8WNKuDAhyjHUUpD7muswT3lRJsO7L8CjL6QvnEUt2oKvtamB2BHBngGTpCwszIMg5hsFNwtgrAah7IYTyTn5IBENh0t4fPI1YIo6utqvh6v4Ywp9GhpcYVE/WtgbzD4W09oj8tO7c0CrJNgcnffq6OWhu8wIZgRdwsqR9GBDkHO2M1pagtpmsZRsU0uaWIyx/s3tj8lzIrgUhyrhO4zgIcoxdHpjul3xyS2UDJ682KlPu4jsMCHKOME7OLuzmNI2jQn7cpRAy3ysqtIla5rhhxcEBIjt5rhwMCHKOzP7ul4Zl7wEoQyL/gDU5JKSUucZJkZ/hWbUD/2QpJyQYEOSYYsvKWX82nfDFJgkwFZxXRssvA4IclBsJoX0zluXslhN2ZWg1DmF6WOs6ncSCSGSkrTpexi4MCHKQtvKD/Yls23quLWQtRH4kpWGb9YlYoaiAtqhwGbswIMhh9oOdylHwAZYMBmexDYLqQZ9cpa0DZR5NaVwZqmBNSimzi8XYLWlpeIiXGBUy/ieUgAFBztJ7N3MLzimGWJuWnBOmZodsG4ahnN3+NFkcB0H1ZP0NZRhYaabuuFQPk+KlRq0xIMgxIhcOBd+gZ7xUKOUMZ7WhOibxfjIgyDlCW51aQGhf4lsKrbkid62hGmLN2kPlyn0PGRDkHGO1ITf1W/EFW3phfXyDyM0TMH0zuPZchv2ZEhUoOhLFFgOCHFP44SvxbC5Ylq6wFUKrjPCqo7YYEOQckf0dJe1Wsxb2caEvO1dQ+xCFy89xKGVFypnmrWFAUFVIqQ27zp3jRWoAtstBaAvX5srYjNymGmBAkMMsMzMdwFWl6ocrSpGzBPRRT9rcClnY3ljYnqmvA5HbKowtk+SM3EStMqZ7MyDIOYYl54S2tJl1uTnDEhHC8rjUZ27ZjrfS96PJyU6I44IxdJmZ1Nfl5aod2uAqBkN9MCDIQYZ1HOzWHlA0NOYbJicsyisOJ3DBGKoLrf3BMBpywo+iTfuEtmYBezUdNonvEWBAkOP0hrCCKkDhh9P248pUqIrJXKYxIMhZ1llaE/V6atPDRb64sGnJZFenAxTzXIphQJBzDF0N+XYFuyVrzY9ooyjz39Zn6OKUUrUrlUvqHZ0lY0CQ82RhN6bM/2gtqt/M7RYi9yeTwSlyEq06DAhyjDkU8r/5S/5Iak+gT84w4CVGXZQVEE899RRuvPFGtLa2orW1FV/84hfxb//2b/p2KSW2bduGrq4uNDQ0YMmSJTh+/LjpOeLxODZs2IBp06ahqakJa9aswdmzZ515NVRfxksL/U6+PqCarKVvzOWC/u2Rhp0mNZaCLKo8WWvWrFnYsWMH3njjDbzxxhv4yle+gj/90z/VQ+DRRx/FY489hieffBKHDh1CKBTC8uXLMTIyoj9Hb28v9u7diz179uC1117D6OgoVq9ejXQ6XfbB02XGNPIxN1kLE5/c2RzIL3tvbHqQKKxM0CSVvKRXXlkBcdddd+GrX/0q5s2bh3nz5uFv//Zv0dzcjNdffx1SSjzxxBPYunUr7rnnHvT09ODZZ5/F+Pg4du/eDQAIh8PYuXMnfvCDH2DZsmW4+eab8dxzz+Ho0aN4+eWXyzpwukJZRkwxHJxXk2/3TqfT2LNnD8bGxvDFL34RJ0+exODgIFasWKGX8fv9WLx4MQ4ePAgAOHz4MJLJpKlMV1cXenp69DJ24vE4IpGI6UaXodyqUNZuSmkuUkBfW0rbzaZFkznhkDKnzZcdEEePHkVzczP8fj8efPBB7N27F5/97GcxODgIAOjs7DSV7+zs1LcNDg7C5/Ohra1NWcZOX18fgsGgfps9e3a5h001ILVutNy6lNqIhmKfR/07fiX0wRD6hCJDbyebIBygdydXcaj1pz/9abz11lt4/fXX8c1vfhP33Xcf3nnnHX27sFxwytzMvmImKrNlyxaEw2H9dubMmXIPm+rE+r864WdTrz4Udn+U0p5BajUZSenz+XD99dfjlltuQV9fH2666Sb8wz/8A0KhEAAU1ASGhob0WkUoFEIikcDw8LCyjB2/36/3nGg3uozp7QjSNADKLhu0EdnZ3k1tBapi34xBk2Zcd6NEFY+DkFIiHo9j7ty5CIVC6O/v17clEgns378fixYtAgAsWLAAXq/XVGZgYADHjh3Ty9AUprU5CMD4Tby20zIMtJ4L09BqSEiRveUeoEpNYvZbWQvG/PVf/zVWrVqF2bNnY2RkBHv27MGvf/1rvPTSSxBCoLe3F9u3b0d3dze6u7uxfft2NDY2Yt26dQCAYDCI+++/H5s2bUJHRwfa29uxefNmzJ8/H8uWLSvvyOmyI6yfQJtUmOiXlz7cWuuSMwzV5uzOyljX+yxFWQHx0Ucf4S/+4i8wMDCAYDCIG2+8ES+99BKWL18OAHj44YcRjUaxfv16DA8PY+HChdi3bx9aWlr053j88cfh8Xiwdu1aRKNRLF26FLt27YLb7S7nUOhypQ1isAsHFDnBjeW1hDD2YpQ8f5yUtOX8yrh4Kysgdu7cWfzfFwLbtm3Dtm3blGUCgQB++MMf4oc//GE5/zRNBcaJWbnuCTlRjSHXSJGdsGUpzEaIuuNcDHKMcd1ImbtEKKgYFNQAtO5QY/1C8HqiWrgmJV1eTC2PtlsnfAbWJOqGAUEOMw6fzF1maCMkDeOmrUvKCWvjZsEACrBGUSHBJeeorkwjH/NBIYwFFLUBUxOEpaFTau1qrElUZDL5yoCg6rF2WSI/UFJAfc4zB6ql/JRlQJBzpOE6QP8smudV2Cn82Mpsw4NxtTleYlRM/37TWo6kJNLpWSAN60FoIyEnOLvzXR8FvZ3WUZY0OcYR8KViQJBjRH4tKDPj6i/WTfYPm2sP5Khy3lMGBDkqOwVDCwpRuKi1qpHSMknLWJQh4ZBJXKIxIMgxUv9Tmj+M6mEQ2c0if1mcvzCxjMJk+4Mjyg1bfrs3OUwUuWdfeqLmCWaDM4rOhVFgDYKclRvQIE0Dr60/2exmHetgGXnN6wwHTOI9ZECQcwzdnKKcvsmCwZeG52AwOIdtEHRZMI5/MCj++RSmGoOpAlF8iQkqWxXXpCRSMv7Gzw1emOijaFq01nD6a98hyfFRzpEi31NUKgYEOSi7ApSwrEminfu2H8xcqAghuRZltUmUGQ8MCKqKfDenMDxUtLhhYVspy29vZ6iUg0OtqW4KT+xiH0flN2fJ/N8cDuGsct5DBgQ5S1tnVpjXggBg6PrUH9D3Md6Edo1SxieZwTExYXyfS8SAIOfkxkAI/Rt4zZ/Fgnka2uQumbvpTyP0nTnc2knatRx7MagOClrI9eHTE8z1Lv6kdqO2qUYYEOSo/ERvwypRli5MGLZre+SGRmlTvMzzN8q72iCViZYYt8GAIAdpjQiw+TYtaVcS+S/7zZXSasBMBMdxyTm6LAllV4WVogdE8tLCObYrdigxIMh5Bee5apSUpVFd2qyIpuj4oMkrZ7AUA4IcIw3daPpS96aNxXaGIS1s5nEwGSrH2ZxUV8auTcOcDKlP0yyym2nBGOjVCGktSJM3iZRlQFBVSaDgC3PUjKmiFTa0WLIhwgHltQAzIMhB+dGT+gCnCU9q4we2cJEZ02gqqogQ5TVQAgwIcpJ2baFfY5QyDtJQTvHLTV97hiom+eW9VD/2vRXFRkLan/fSUmPIL6fPq4zJ099RzsWgeipc6sX6t1G2FdOUB3bF1D2lVJbyqmIMCHJOLhPyQ6fN0aDufxfZqq/1isRy5cGrDAdoE+lKxIAgB1lPY+2yIN84Zv1sCmvVwNJ+Yb1kZkhUwq4RuDgGBDlPm/IN48Becwu6XY3A9rt/UUpPCJVkgvEodhgQ5BzTOpS5Lk/TnE1zUdN5b+wbza0/J3lt4axJLPjJgCCHCZt7pYz+t5/7WX6lmIpjNyfVibDOt7D89lc3URouI/TfcuYVpcgJIve2ciQl1YPQVpWyaUgoQrsY0edy2PSK8irDKWyDoDrJNh1oC8bYJ0PBQCmbNgbrBYk20ZMcUObqXAwIqoL89YJtT4Wd7Kwuw1JUIn+pYXhW9mjUFgOCnGeYhSkkTF+KY6XlgQAgpMzecnUIYbOWJU1edvVwNlJSvWgjH4X2R36wU7GPZX4NCONj0rzGDBshHJBfHLhUDAhyTMFiUHYzM+0+m8ZgEOawkJa1JJgTlWIjJdWNdj0hYdeDUfT3lnEstsyNuzQsNSWN22mScv8pnM1JdWGakZnrvJxgLoXWXCGM686h8JKDHMTJWlQPE42XLH0qQJl9cVSSybylDAhynN5GaZrHCW1wZEHZ7CYBmwER2TKsSThDwPbSrxgGBDks9wk0LTib782wvcSAZcSE3QeYNYrKTaKVlwFBVaJYZ7L48pMGht4LhoNDpOmvUjAgyDmGkz87CFIYGhuLD702tlEKabMLLzMcwm5OqhfT5CrrInPmD6Z1QRh97obIjn0oXHmKKqYNZS8DA4IcUzADwzh1uwj9csO6QIz9cAqqFBspqR6kmHitAfVnUyrLcASl07geBNWDPt1b5C4ZJogL67JyuSqwFMYRf+XOHiAlibJbfBkQ5DyZ/0FI88Omz6cw/yi0YdraY5bhlJzuXSn2YtBlQxa5l2ed6ZmvdxQ2VJJTOJuT6kC7MtCne0vzb3+9jInM91qYujYAiOw2bZAl2yIqNInaFwOCHDSZ2ZzmGYbmqwyhz/8uc50TsjOJGXAMCKop1WzOQooPMqsQk6b+fjM1BgQ5x/hr3jDdu5RRENbp3lQFuW7oct7ligKir68PQgj09vbqj0kpsW3bNnR1daGhoQFLlizB8ePHTfvF43Fs2LAB06ZNQ1NTE9asWYOzZ89Wcih0GchPvDLO5jQMp7ZtRNCaJYX5Gdjg4Dh91fEyTDogDh06hJ/85Ce48cYbTY8/+uijeOyxx/Dkk0/i0KFDCIVCWL58OUZGRvQyvb292Lt3L/bs2YPXXnsNo6OjWL16NdLp9GQPhy4bRdaUm2QFgV2bTqtyL8bo6Cj+/M//HE8//TTa2tr0x6WUeOKJJ7B161bcc8896OnpwbPPPovx8XHs3r0bABAOh7Fz50784Ac/wLJly3DzzTfjueeew9GjR/Hyyy9P5nDosiNMjQtao6MwLAhROMnTMt3buBaldQg2VaSct3FSAfGtb30Ld955J5YtW2Z6/OTJkxgcHMSKFSv0x/x+PxYvXoyDBw8CAA4fPoxkMmkq09XVhZ6eHr2MVTweRyQSMd3oMmSazZntgch/J2/xWRXW2ZyGZSTyz82aRGUm8R56yv039uzZgzfffBOHDh0q2DY4OAgA6OzsND3e2dmJU6dO6WV8Pp+p5qGV0fa36uvrwyOPPFLuoVKtSWstwPCz9qNlHlfJn1fWHiomUH5VrKyAOHPmDL797W9j3759CAQC6gOxXDRKKZVfxVZKmS1btmDjxo36/UgkgtmzZ8Pjck/4vFR9brcbAJCOA6mYRAoSSa+EO5OBK51B3JWBK52CTAggkULalx0nmUymEI2lkUikkYinkRjPIBHLIBnLIBkDUjEgE8/eZEJAJgWQdAEpV+GUglS2Mux2ueF1l/1774pm/P9JxwCZqlJAHD58GENDQ1iwYIH+WDqdxoEDB/Dkk0/ixIkTALK1hBkzZuhlhoaG9FpFKBRCIpHA8PCwqRYxNDSERYsW2f67fr8ffr+/4PFVNy+G18MPQ71pEf2/f+YCkAEQhUDUvLFUBdMFPACaczdYNxYcya3XzWdlw0L7L3j3p9n/n2QqVfK+ZZ1dS5cuxdGjR02PfeMb38ANN9yA73znO7j22msRCoXQ39+Pm2++GQCQSCSwf/9+/N3f/R0AYMGCBfB6vejv78fatWsBAAMDAzh27BgeffTRcg4H/3njp9HYWBgcRKQ2Ph7Hz//8/y2pbFkB0dLSgp6eHtNjTU1N6Ojo0B/v7e3F9u3b0d3dje7ubmzfvh2NjY1Yt24dACAYDOL+++/Hpk2b0NHRgfb2dmzevBnz588vaPScSPeSZrQEA/B5fUXLpdNppNLFU9Pr9cFV5HJFSolEMlH0OdxuNzwTVG+TySQyMqPcLoTg67HB11Nosq9nNOItuo+R4/Xzhx9+GNFoFOvXr8fw8DAWLlyIffv2oaWlRS/z+OOPw+PxYO3atYhGo1i6dCl27dqlXyuVaveRX6Ep6Mf1184r2hZx8eMLGPrDR0Wf61NzrkVDQ4NyezKZxPsf/K7oc7S3daBzeqhomZOnfo9YLKbc7vF4+Hps8PUUmuzriY+VPt5ISDn11gyORCIIBoPYeuCPMb2rA40Njbb/YVJKnB84h1gsqkxjn8+Hzukz0BBoUAbU8KWPEYmEMR4dVx5T14yZCAQa4PfZX/LE43F8NDSAaCyKTMb+N9RVwTa0tgb5evh6qvp64mNpPLn6OMLhMFpbW5X/BlCFGkQtNTU1oamxyXZbKpVCPB7D2Ngo0hn7xPT7/GhsbEJzU7PtdiklxqPjGBsbVf5nud1u+P0BNDU1K6t7sXgM4+NjGBsfU76WxoZGNDU18/Xw9dTk9ZRqSgdES7M6/cbHx3BuoPj8jmnTpqO1Rf0cUkqcOXsKxSpZjY1NmNU1u+i/c+HCEEZGR5TbhRCYPesauFzqcWt8PYX4euxN9HrKMaUDQuXs+TOIFqmeud1uXDP7U/B41I01l8LDuPjxhaL/WTNnzEJDQ6NyeyqVwqkzHyKVSirLBFuvQkf7tKLXtHw9hfh6CpX6eho7WgEcV5YxuqICIpVKYXRsBLFoFClFX28g0IDGhkb4fH7ldWRkJIKxsVEkEvbXkW63G81NLQg0NMDrtf9Pj0bHMR4dRyIRVx5va0srmpqabcd48PXw9VTr9fiEepCj1RUTEFq30MDg+aLlgq1BtLd1KJ8DAIaGBot2U/m8PnTNmFn0OcKRMIYvfVz0WKZPD8Gr+K3C16M+Fr6ewuco5/VER9Q1DKsrJiAGBs9NeB153bXdcLvUXamjoyM4P3geGUUjEwDMCM1ES3OLcruUEr//4D1lQxUANDe3oCvUBVeRY+HrKcTXU8ip16My5QMinU7j4+GLiMZiyu6pQKABzblWX9W15KVLwxgdH1X+Z7lcLrS3daAhEFB2T0Wj4xgdGy362yAYvArNjc1wK1qg+Xr4emr5eiYypQMiGU8BLoGhj4aKlvN7AriqpR2phDplL164iFhcPUDG5RG4qqU9/+/aGImM4g8Xih9LS2MQAX9A+RypVIqvxwZfT6HJvh7V89mZ0gOl/tOWT8EbsJnZZyUmnjOkXjzVweco9Xn4eso/Fr6ekp8nGctgb9+HV/5AqT+5uhMNDVP6JRDVXDSawl58WFLZKX12LZjehebG0ieeEBEwOv4J6cXw3vDH8DWrJ7wQUSHvaBTA3pLK8nsxiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiJAUFESgwIIlJiQBCREgOCiJQYEESkxIAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhIiQFBREoMCCJSYkAQkRIDgoiUGBBEpMSAICIlBgQRKTEgiEiprIDYtm0bhBCmWygU0rdLKbFt2zZ0dXWhoaEBS5YswfHjx03PEY/HsWHDBkybNg1NTU1Ys2YNzp4968yrISJHlV2D+NznPoeBgQH9dvToUX3bo48+isceewxPPvkkDh06hFAohOXLl2NkZEQv09vbi71792LPnj147bXXMDo6itWrVyOdTjvziojIMZ6yd/B4TLUGjZQSTzzxBLZu3Yp77rkHAPDss8+is7MTu3fvxgMPPIBwOIydO3fiZz/7GZYtWwYAeO655zB79my8/PLLWLlyZYUvh4icVHYN4r333kNXVxfmzp2LP/uzP8MHH3wAADh58iQGBwexYsUKvazf78fixYtx8OBBAMDhw4eRTCZNZbq6utDT06OXsROPxxGJREw3Iqq+sgJi4cKF+OlPf4p///d/x9NPP43BwUEsWrQIFy9exODgIACgs7PTtE9nZ6e+bXBwED6fD21tbcoydvr6+hAMBvXb7NmzyzlsIpqksgJi1apV+NrXvob58+dj2bJl+OUvfwkgeymhEUKY9pFSFjxmNVGZLVu2IBwO67czZ86Uc9hENEkVdXM2NTVh/vz5eO+99/R2CWtNYGhoSK9VhEIhJBIJDA8PK8vY8fv9aG1tNd2IqPoqCoh4PI53330XM2bMwNy5cxEKhdDf369vTyQS2L9/PxYtWgQAWLBgAbxer6nMwMAAjh07ppchostHWb0Ymzdvxl133YU5c+ZgaGgI3//+9xGJRHDfffdBCIHe3l5s374d3d3d6O7uxvbt29HY2Ih169YBAILBIO6//35s2rQJHR0daG9vx+bNm/VLFiK6vJQVEGfPnsXXv/51XLhwAVdffTVuu+02vP7667jmmmsAAA8//DCi0SjWr1+P4eFhLFy4EPv27UNLS4v+HI8//jg8Hg/Wrl2LaDSKpUuXYteuXXC73c6+MiKqmJBSynofRLkikQiCwSB++8bfo6W5od6HQzSljIxGcdMtmxEOhydszyt7oNTlQMu00dFYnY+EaOrRzptS6gZTsgZx9uxZjoUgqtCZM2cwa9asomWmZEBkMhmcOHECn/3sZ3HmzBl2e9qIRCKYPXs23x+FT/L7I6XEyMgIurq64HIV78ickpcYLpcLM2fOBACOi5gA35/iPqnvTzAYLKkc14MgIiUGBBEpTdmA8Pv9+N73vge/31/vQ7ks8f0pju9PaaZkIyUR1caUrUEQUfUxIIhIiQFBREoMCCJSmpIB8aMf/Qhz585FIBDAggUL8Jvf/Kbeh1QTBw4cwF133YWuri4IIfDiiy+atn/Sv3agr68Pt956K1paWjB9+nTcfffdOHHihKnMJ/09KpucYvbs2SO9Xq98+umn5TvvvCO//e1vy6amJnnq1Kl6H1rV/epXv5Jbt26Vzz//vAQg9+7da9q+Y8cO2dLSIp9//nl59OhRee+998oZM2bISCSil3nwwQflzJkzZX9/v3zzzTflHXfcIW+66SaZSqVq/Gqct3LlSvnMM8/IY8eOybfeekveeeedcs6cOXJ0dFQv80l/j8o15QLiC1/4gnzwwQdNj91www3yu9/9bp2OqD6sAZHJZGQoFJI7duzQH4vFYjIYDMof//jHUkopL126JL1er9yzZ49e5ty5c9LlcsmXXnqpZsdeK0NDQxKA3L9/v5SS79FkTKlLjEQigcOHD5uWzQeAFStWFF02/5Ogml87MFWFw2EAQHt7OwC+R5MxpQLiwoULSKfTRZfW/6Sq5tcOTEVSSmzcuBG33347enp6APA9mowpOZtzMkvrf1JU42sHpqKHHnoIb7/9Nl577bWCbXyPSjelahDTpk2D2+0uurT+J1U1v3ZgqtmwYQN+8Ytf4NVXXzUtiML3qHxTKiB8Ph8WLFhgWjYfAPr7+z/xy+bzaweyv+UfeughvPDCC3jllVcwd+5c03a+R5NQxwbSSdG6OXfu3Cnfeecd2dvbK5uamuSHH35Y70OrupGREXnkyBF55MgRCUA+9thj8siRI3oX744dO2QwGJQvvPCCPHr0qPz6179u24U3a9Ys+fLLL8s333xTfuUrX7liuvC++c1vymAwKH/961/LgYEB/TY+Pq6X+aS/R+WacgEhpZT/+I//KK+55hrp8/nk5z//eb0b60r36quvSgAFt/vuu09Kme3G+973vidDoZD0+/3yy1/+sjx69KjpOaLRqHzooYdke3u7bGhokKtXr5anT5+uw6txnt17A0A+88wzeplP+ntULk73JiKlKdUGQUS1xYAgIiUGBBEpMSCISIkBQURKDAgiUmJAEJESA4KIlBgQRKTEgCAiJQYEESkxIIhI6f8Ab4SO9qXUT8cAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image.transpose([1, 0, 2]))\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the transformed image: (288, 512, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def resize_gray(frame):\n",
    "    frame = cv2.cvtColor(cv2.resize(frame, (80, 80)), cv2.COLOR_BGR2GRAY)\n",
    "    ret, frame = cv2.threshold(frame, 1, 255, cv2.THRESH_BINARY)\n",
    "    return np.reshape(frame, (80, 80, 1))\n",
    "\n",
    "image_transformed = resize_gray(image)\n",
    "print('Shape of the transformed image:', image.shape)\n",
    "\n",
    "# show the transformed image\n",
    "_ = plt.imshow(image_transformed.transpose((1, 0, 2)), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image_raw, current_state=None):\n",
    "    # resize and convert to grayscale\n",
    "    image = resize_gray(image_raw)\n",
    "    # stack the frames\n",
    "    if current_state is None:\n",
    "        state = np.concatenate((image, image, image, image), axis=2)\n",
    "    else:\n",
    "        state = np.concatenate((image, current_state[:, :, :3]), axis=2)\n",
    "    return state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Constructing the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import initializers\n",
    "def create_q_model():\n",
    "    state = layers.Input(shape=(80, 80, 4,))\n",
    "\n",
    "    layer1 = layers.Conv2D(filters=32, kernel_size=8, strides=4, activation=\"relu\",\n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(state)\n",
    "    layer2 = layers.MaxPool2D(2, strides=2, padding=\"SAME\")(layer1)\n",
    "    layer3 = layers.Conv2D(filters=64, kernel_size=4, strides=2, activation=\"relu\", \n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    q_value = layers.Dense(units=2, activation=\"linear\", \n",
    "                           kernel_initializer=initializers.TruncatedNormal(mean=0., stddev=0.01),\n",
    "                           bias_initializer=initializers.Constant(0.01))(layer4)\n",
    "\n",
    "    return keras.Model(inputs=state, outputs=q_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the model summary to make sure that the network is the same as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 80, 80, 4)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 19, 19, 32)        8224      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 10, 10, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 4, 4, 64)          32832     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 2)                 2050      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43106 (168.38 KB)\n",
      "Trainable params: 43106 (168.38 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_q_model()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deep Q-learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = 0.99            # decay rate of past observations\n",
    "step_size = 1e-4        # step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "observe = 10000            # timesteps to observe before training\n",
    "replay_memory = 10000      # number of previous transitions to remember\n",
    "batch_size = 32            # size of each batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value of epsilon\n",
    "epsilon = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dql_flappy_bird(model, optimizer, loss_function):\n",
    "\n",
    "    # initiate a game\n",
    "    game = flappy_bird.GameState()\n",
    "\n",
    "    # store the previous state, action and transitions\n",
    "    history_data = deque()\n",
    "\n",
    "    # get the first observation by doing nothing and preprocess the image\n",
    "    do_nothing = np.zeros(num_actions)\n",
    "    do_nothing[0] = 1\n",
    "    image, reward, terminal = game.frame_step(do_nothing)\n",
    "\n",
    "    # preprocess to get the state\n",
    "    current_state = preprocess(image_raw=image)\n",
    "    \n",
    "    # training\n",
    "    t = 0\n",
    "\n",
    "    while t < 50000:\n",
    "        if epsilon > np.random.rand(1)[0]:\n",
    "            # random action\n",
    "            action = np.random.choice(num_actions)\n",
    "        else:\n",
    "            # compute the Q function\n",
    "            current_state_tensor = tf.convert_to_tensor(current_state)\n",
    "            current_state_tensor = tf.expand_dims(current_state_tensor, 0)\n",
    "            q_value = model(current_state_tensor, training=False)\n",
    "            \n",
    "            # greedy action\n",
    "            # your code here\n",
    "            #-----------------#\n",
    "            action = np.argmax(q_value.numpy()) \n",
    "\n",
    "        # take the action and observe the reward and the next state\n",
    "        action_vec = np.zeros([num_actions])\n",
    "        action_vec[action] = 1\n",
    "        image_raw, reward, terminal = game.frame_step(action_vec)\n",
    "        next_state = preprocess(current_state=current_state, \n",
    "                                image_raw=image_raw)\n",
    "        \n",
    "        # store the observation\n",
    "        history_data.append((current_state, action, reward, next_state, \n",
    "                            terminal))\n",
    "        if len(history_data) > replay_memory:\n",
    "            history_data.popleft()  # discard old data\n",
    "\n",
    "        # train if done observing\n",
    "        if t > observe:\n",
    "\n",
    "            # sample a batch\n",
    "            batch = random.sample(history_data, batch_size)\n",
    "            state_sample = np.array([d[0] for d in batch])\n",
    "            action_sample = np.array([d[1] for d in batch])\n",
    "            reward_sample = np.array([d[2] for d in batch])\n",
    "            state_next_sample = np.array([d[3] for d in batch])\n",
    "            terminal_sample = np.array([d[4] for d in batch])\n",
    "\n",
    "            # compute the updated Q-values for the samples\n",
    "            # your code here\n",
    "            #-----------------#\n",
    "            # Inside the training loop, after sampling a batch\n",
    "            current_q_values = model(tf.convert_to_tensor(state_sample), training=True)\n",
    "            current_q_values_actions = tf.reduce_sum(\n",
    "            current_q_values * tf.one_hot(action_sample, depth=num_actions), axis=1)\n",
    "\n",
    "            q_values_next = model(tf.convert_to_tensor(state_next_sample), training=False)\n",
    "            max_q_values_next = tf.reduce_max(q_values_next, axis=1)\n",
    "\n",
    "            # Compute the updated Q-values\n",
    "            # Your existing calculation of updated_q_value is correct\n",
    "            updated_q_value = reward_sample + gamma * (1 - terminal_sample) * max_q_values_next\n",
    "\n",
    "\n",
    "            # train the model on the states and updated Q-values\n",
    "            with tf.GradientTape() as tape:\n",
    "                # compute the current Q-values for the samples\n",
    "                # your code here\n",
    "                #-----------------#\n",
    "                current_q_values = model(tf.convert_to_tensor(state_sample), training=True)\n",
    "                current_q_values_actions = tf.reduce_sum(current_q_values * tf.one_hot(action_sample, depth=num_actions), axis=1)\n",
    "\n",
    "                # compute the loss\n",
    "                loss = loss_function(updated_q_value, current_q_values_actions)\n",
    "\n",
    "            # backpropagation\n",
    "            grads = tape.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        else:\n",
    "            loss = 0\n",
    "\n",
    "        # update current state and counter\n",
    "        current_state = next_state\n",
    "        t += 1\n",
    "\n",
    "        # print info every 500 steps\n",
    "        if t % 500 == 0:\n",
    "            print(f\"STEP {t} | PHASE {'observe' if t<=observe else 'train'}\", \n",
    "                  f\"| ACTION {action} | REWARD {reward} | LOSS {loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def playgame(start_from_ckpt=False, ckpt_path=None):\n",
    "\n",
    "    np.random.seed(4)\n",
    "\n",
    "    if start_from_ckpt:\n",
    "        # if you want to start from a checkpoint\n",
    "        model = keras.models.load_model('ckpt_path')\n",
    "    else:\n",
    "        model = create_q_model()\n",
    "\n",
    "    # specify the optimizer and loss function\n",
    "    optimizer = keras.optimizers.legacy.Adam(learning_rate=step_size, clipnorm=1.0)\n",
    "    loss_function = keras.losses.MeanSquaredError()\n",
    "\n",
    "    # play the game\n",
    "    dql_flappy_bird(model=model, optimizer=optimizer, loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 1000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 1500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 2000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 2500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 3000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 3500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 4000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 4500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 5000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 5500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 6000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 6500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 7000 | PHASE observe | ACTION 0 | REWARD 0.1 | LOSS 0\n",
      "STEP 7500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 8000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 8500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 9000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 9500 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 10000 | PHASE observe | ACTION 1 | REWARD 0.1 | LOSS 0\n",
      "STEP 10500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 1259.7823486328125\n",
      "STEP 11000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.8198993802070618\n",
      "STEP 11500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.012598698027431965\n",
      "STEP 12000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.020820414647459984\n",
      "STEP 12500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.012317176908254623\n",
      "STEP 13000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.00954309944063425\n",
      "STEP 13500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.021767841652035713\n",
      "STEP 14000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.0012759806122630835\n",
      "STEP 14500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.013049760833382607\n",
      "STEP 15000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0030686864629387856\n",
      "STEP 15500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0010717310942709446\n",
      "STEP 16000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0031231814064085484\n",
      "STEP 16500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.002450647298246622\n",
      "STEP 17000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0019522160291671753\n",
      "STEP 17500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.0006912692915648222\n",
      "STEP 18000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0026884106919169426\n",
      "STEP 18500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.0011366951512172818\n",
      "STEP 19000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.002228756435215473\n",
      "STEP 19500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.002025079447776079\n",
      "STEP 20000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.004172800574451685\n",
      "STEP 20500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.06418251991271973\n",
      "STEP 21000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.006711536552757025\n",
      "STEP 21500 | PHASE train | ACTION 0 | REWARD -1 | LOSS 0.0032916003838181496\n",
      "STEP 22000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.002019367180764675\n",
      "STEP 22500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.003587262472137809\n",
      "STEP 23000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.0078970305621624\n",
      "STEP 23500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.002588322851806879\n",
      "STEP 24000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.021686948835849762\n",
      "STEP 24500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.01002617459744215\n",
      "STEP 25000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.02280711941421032\n",
      "STEP 25500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.019761135801672935\n",
      "STEP 26000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.05925070866942406\n",
      "STEP 26500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.013805294409394264\n",
      "STEP 27000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.021395761519670486\n",
      "STEP 27500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.015209188684821129\n",
      "STEP 28000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.06869339942932129\n",
      "STEP 28500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.04143666848540306\n",
      "STEP 29000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.03683272376656532\n",
      "STEP 29500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.10858689248561859\n",
      "STEP 30000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.08541391044855118\n",
      "STEP 30500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.054797522723674774\n",
      "STEP 31000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.03745393082499504\n",
      "STEP 31500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0877324640750885\n",
      "STEP 32000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2686648964881897\n",
      "STEP 32500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.17127788066864014\n",
      "STEP 33000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1341182440519333\n",
      "STEP 33500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.046778544783592224\n",
      "STEP 34000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 2.598423480987549\n",
      "STEP 34500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.13086488842964172\n",
      "STEP 35000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.14951573312282562\n",
      "STEP 35500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.21908479928970337\n",
      "STEP 36000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.24633219838142395\n",
      "STEP 36500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.28735214471817017\n",
      "STEP 37000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.19632703065872192\n",
      "STEP 37500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2959986925125122\n",
      "STEP 38000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3312186300754547\n",
      "STEP 38500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.1402239352464676\n",
      "STEP 39000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.09738542139530182\n",
      "STEP 39500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.29620030522346497\n",
      "STEP 40000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.31211239099502563\n",
      "STEP 40500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.24767619371414185\n",
      "STEP 41000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.25816553831100464\n",
      "STEP 41500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 1.5990506410598755\n",
      "STEP 42000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.22706133127212524\n",
      "STEP 42500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.21917903423309326\n",
      "STEP 43000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.20708191394805908\n",
      "STEP 43500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.7884665727615356\n",
      "STEP 44000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.25545406341552734\n",
      "STEP 44500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.15745963156223297\n",
      "STEP 45000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.21844205260276794\n",
      "STEP 45500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3183385729789734\n",
      "STEP 46000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3085075318813324\n",
      "STEP 46500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.17203405499458313\n",
      "STEP 47000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2714937925338745\n",
      "STEP 47500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 3.7949624061584473\n",
      "STEP 48000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.45709672570228577\n",
      "STEP 48500 | PHASE train | ACTION 0 | REWARD -1 | LOSS 0.11490093171596527\n",
      "STEP 49000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.19238924980163574\n",
      "STEP 49500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.2178839147090912\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6v/hyhcb5812t3db6vvj6md0fxh0000gn/T/ipykernel_9764/981574388.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplaygame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6v/hyhcb5812t3db6vvj6md0fxh0000gn/T/ipykernel_9764/811619736.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(start_from_ckpt, ckpt_path)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclipnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mloss_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMeanSquaredError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# play the game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdql_flappy_bird\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/6v/hyhcb5812t3db6vvj6md0fxh0000gn/T/ipykernel_9764/4292783836.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(model, optimizer, loss_function)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;31m# compute the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_q_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_q_values_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;31m# backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1062\u001b[0m               output_gradients))\n\u001b[1;32m   1063\u001b[0m       output_gradients = [None if x is None else ops.convert_to_tensor(x)\n\u001b[1;32m   1064\u001b[0m                           for x in output_gradients]\n\u001b[1;32m   1065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1066\u001b[0;31m     flat_grad = imperative_grad.imperative_grad(\n\u001b[0m\u001b[1;32m   1067\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mflat_targets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     63\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     raise ValueError(\n\u001b[1;32m     65\u001b[0m         \"Unknown value for unconnected_gradients: %r\" % unconnected_gradients)\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m   return pywrap_tfe.TFE_Py_TapeGradient(\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tape\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"gradient_tape/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    590\u001b[0m           \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m           data_format=data_format),\n\u001b[0;32m--> 594\u001b[0;31m       gen_nn_ops.conv2d_backprop_filter(\n\u001b[0m\u001b[1;32m    595\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m           \u001b[0mshape_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m           \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.11/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1495\u001b[0m         data_format, \"dilations\", dilations)\n\u001b[1;32m   1496\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1497\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1499\u001b[0;31m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1500\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m       return conv2d_backprop_filter_eager_fallback(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "playgame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following was a test to see performance with only 100 steps before the training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 2.422938108444214\n",
      "STEP 1000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.12893174588680267\n",
      "STEP 1500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.025578347966074944\n",
      "STEP 2000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.020953886210918427\n",
      "STEP 2500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.07277293503284454\n",
      "STEP 3000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.015047937631607056\n",
      "STEP 3500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.009646087884902954\n",
      "STEP 4000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.025542743504047394\n",
      "STEP 4500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0069857025519013405\n",
      "STEP 5000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.006203163880854845\n",
      "STEP 5500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.0075559127144515514\n",
      "STEP 6000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.016295243054628372\n",
      "STEP 6500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.008017242886126041\n",
      "STEP 7000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.006555842235684395\n",
      "STEP 7500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.003314489033073187\n",
      "STEP 8000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.01739364117383957\n",
      "STEP 8500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.021394457668066025\n",
      "STEP 9000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.038576848804950714\n",
      "STEP 9500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.034960225224494934\n",
      "STEP 10000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.019603922963142395\n",
      "STEP 10500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.02009761333465576\n",
      "STEP 11000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.04050962254405022\n",
      "STEP 11500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.13017871975898743\n",
      "STEP 12000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.017553366720676422\n",
      "STEP 12500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.028895070776343346\n",
      "STEP 13000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.10522431135177612\n",
      "STEP 13500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.10664823651313782\n",
      "STEP 14000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.06327357143163681\n",
      "STEP 14500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.08088968694210052\n",
      "STEP 15000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.0547637939453125\n",
      "STEP 15500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.08039796352386475\n",
      "STEP 16000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.10816794633865356\n",
      "STEP 16500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.17359676957130432\n",
      "STEP 17000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2759324610233307\n",
      "STEP 17500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.11637525260448456\n",
      "STEP 18000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.19080916047096252\n",
      "STEP 18500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3765735626220703\n",
      "STEP 19000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.08709901571273804\n",
      "STEP 19500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3480122983455658\n",
      "STEP 20000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.17152786254882812\n",
      "STEP 20500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.15766867995262146\n",
      "STEP 21000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.4353175163269043\n",
      "STEP 21500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.23572348058223724\n",
      "STEP 22000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.24242699146270752\n",
      "STEP 22500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3036676049232483\n",
      "STEP 23000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.15988580882549286\n",
      "STEP 23500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.25992703437805176\n",
      "STEP 24000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.20286859571933746\n",
      "STEP 24500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.30782729387283325\n",
      "STEP 25000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1250855028629303\n",
      "STEP 25500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.15230408310890198\n",
      "STEP 26000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.23871612548828125\n",
      "STEP 26500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 1.499967336654663\n",
      "STEP 27000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 2.134018898010254\n",
      "STEP 27500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2699841558933258\n",
      "STEP 28000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.37060466408729553\n",
      "STEP 28500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.12460704147815704\n",
      "STEP 29000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.4257110357284546\n",
      "STEP 29500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.16329094767570496\n",
      "STEP 30000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.4677806496620178\n",
      "STEP 30500 | PHASE train | ACTION 0 | REWARD -1 | LOSS 0.13330888748168945\n",
      "STEP 31000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.19962634146213531\n",
      "STEP 31500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.8187220096588135\n",
      "STEP 32000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.1913384050130844\n",
      "STEP 32500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.13231754302978516\n",
      "STEP 33000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.13271605968475342\n",
      "STEP 33500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.2190379649400711\n",
      "STEP 34000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.5211819410324097\n",
      "STEP 34500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.30209922790527344\n",
      "STEP 35000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.35963940620422363\n",
      "STEP 35500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.08964992314577103\n",
      "STEP 36000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.132878839969635\n",
      "STEP 36500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1789495348930359\n",
      "STEP 37000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.4847419857978821\n",
      "STEP 37500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.21758227050304413\n",
      "STEP 38000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.26316672563552856\n",
      "STEP 38500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.1885192096233368\n",
      "STEP 39000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.20601022243499756\n",
      "STEP 39500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1006239801645279\n",
      "STEP 40000 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.5038958787918091\n",
      "STEP 40500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 2.397826671600342\n",
      "STEP 41000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.3408889174461365\n",
      "STEP 41500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.10423536598682404\n",
      "STEP 42000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.25089210271835327\n",
      "STEP 42500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.15588709712028503\n",
      "STEP 43000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.28275614976882935\n",
      "STEP 43500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.970893383026123\n",
      "STEP 44000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.8458482027053833\n",
      "STEP 44500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.23550169169902802\n",
      "STEP 45000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.12022347003221512\n",
      "STEP 45500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.5856949090957642\n",
      "STEP 46000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1585310399532318\n",
      "STEP 46500 | PHASE train | ACTION 0 | REWARD 1 | LOSS 0.21348625421524048\n",
      "STEP 47000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.33588361740112305\n",
      "STEP 47500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.18248350918293\n",
      "STEP 48000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 6.471296787261963\n",
      "STEP 48500 | PHASE train | ACTION 1 | REWARD 0.1 | LOSS 0.15629267692565918\n",
      "STEP 49000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.23685981333255768\n",
      "STEP 49500 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.10625089704990387\n",
      "STEP 50000 | PHASE train | ACTION 0 | REWARD 0.1 | LOSS 0.1839979887008667\n"
     ]
    }
   ],
   "source": [
    "observe = 100            # timesteps to observe before training\n",
    "playgame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This had a similar performance near the final steps but showed much quicker training and much faster improvement. Bird passed first pipe at step 10000 and played near perfectly by 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
